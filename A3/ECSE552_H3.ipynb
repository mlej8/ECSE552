{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECSE552 - H3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlej8/ECSE552/blob/main/ECSE552_H3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU8fF5G7hvq-"
      },
      "source": [
        "# ECSE - Homework 3\n",
        "Released: 10 February 2021\n",
        "\n",
        "Due: 23 February 2021\n",
        "\n",
        "Last Modified: 10 February 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifGZ2dWjiBDe"
      },
      "source": [
        "## Part 1 - Data Augmentation (36 pts)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "In Tutorial 3, a Twin neural network architecture was used to test if two images matched.\n",
        "\n",
        "Data Augementation is a method by which data inputted to a model is altered in ways that *don't change the label* of the category so that the model might *learn from more diverse samples*. This is often done to avoid overfitting and creating fragile models.\n",
        "\n",
        "PyTorch offers a simple way to apply transformations to [`torchvision`](https://pytorch.org/vision/0.8/) datasets using the `transform` argument of datasets in the [`torchvision.datasets`](https://pytorch.org/vision/0.8/datasets.html) module. An example of this is available in Tutorial 3.\n",
        "\n",
        "You are tasked with the following:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DC4Nazsjqqq"
      },
      "source": [
        "### Q1.1: Choosing Transformations (9 pts)\n",
        "\n",
        "Please **list at least 3 transformations** that would be applicable to the Twin neural network *as applied to the digit matching task* from Tutorial 3.\n",
        "\n",
        "Please also give a **very brief (~1-2 sentence) explanation** as to what sort of variance each transformation will introduce to the data, and why that might be favorable.\n",
        "\n",
        "Assure that at least one of the listed transformations are implemented by the [`torchvision.transforms`](https://pytorch.org/docs/stable/torchvision/transforms.html) [API](https://www.howtogeek.com/343877/what-is-an-api/). You can do this by simply reading function names and descriptions there and cross-referencing with your list. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1NNRkWsqnMu"
      },
      "source": [
        "1. Transformation 1 - Explanation\n",
        "\n",
        "2. Transformation 2 - Explanation\n",
        "\n",
        "3. Transformation 3 - Explanation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D421iY6Dt3BE"
      },
      "source": [
        "### Q1.2 Implementing Custom Transformations (17 pts)\n",
        "\n",
        "It would be helpful to add pixel-level noise to the digit samples, but the [`torchvision.transforms`](https://pytorch.org/docs/stable/torchvision/transforms.html) API does not have such a transform.\n",
        "\n",
        "**Implement your own noise transform using the template code below.**\n",
        "\n",
        "#### Hints\n",
        "\n",
        "You can add random noise however you like, but assure that letters in the images are still legible (*i.e.:* the signal-to-noise ratio is still high). You can eye-ball it, just use a small conservatively small value if you are concerned.\n",
        "\n",
        "Below are some images of how your noise might look. In this example, the amount of noise is added with a random probability, and the amount of noise added is capped at some level to assure legibility.\n",
        "\n",
        "(You can alternatively add random noise with consistant probability)\n",
        "\n",
        "![Noise applied to the USPS digits set](https://dl.sphericalcow.xyz/ecse552/H3/usps_noise.png)\n",
        "\n",
        "![Noise applied to the MNIST digits set](https://dl.sphericalcow.xyz/ecse552/H3/mnist_noise.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDGwPeU2ul4V"
      },
      "source": [
        "# Q1.2 code here\n",
        "\n",
        "class AddNoise(object):\n",
        "    def __init__(self,\n",
        "                 # you can add parameters here\n",
        "                 raffaella = 5353456\n",
        "                 ):\n",
        "        \n",
        "        # you can store variables in the object (we call them \"properties\")\n",
        "        # here, I'm storing the integer 8675309 to a variable named jenny\n",
        "        self.jenny = 8675309\n",
        "\n",
        "        # you can store function parameters too\n",
        "        self.raffaella = raffaella\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        # this function is called on each transform\n",
        "        # the tensor parameter is the sample to be transformed\n",
        "        # `tensor` is a matrix which represents the image with values from 0-1\n",
        "        # Your task is to add random values to `tensor`. \n",
        "        # Hint: Generate a random matrix with the same size as `tensor` and add\n",
        "        # it to `tensor`\n",
        "\n",
        "        # you can use properties of your object you defined in __init__\n",
        "        assert self.jenny == 8675309\n",
        "        assert self.raffaella == 5353456\n",
        "        \n",
        "        # this transform doesn't do anything other but output what is inputted\n",
        "        return tensor\n",
        "    \n",
        "    def __repr__(self):\n",
        "        # you can ignore this if you like\n",
        "        # return here a string representation of your transform\n",
        "        # you can include parameters in it should you like\n",
        "        # this one just returns the class name\n",
        "        return self.__class__.__name__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlP7bovkrc16"
      },
      "source": [
        "### Q1.3 Applying the Transformations (5 pts)\n",
        "\n",
        "**Define an instance of [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)** for both the USPS and MNIST datasets, much like was done in Tutorial 3. You may reuse the code from there.\n",
        "\n",
        "Just like in Tutorial 3, name those instances of Dataset: `usps_trainset`, `usps_testset`, `mnist_trainset`, `mnist_testset` according to whether they belong to MNIST or USPS, and if they are training or test splits.\n",
        "\n",
        "Also, just like in Tutorial 3, name a variable `transform` and use [`torchvision.transforms.Compose`](https://pytorch.org/vision/0.8/transforms.html#torchvision.transforms.Compose) to **compose the following transformations:**\n",
        "\n",
        "1. At least one transformation you listed in Q1.1\n",
        "2. The AddNoise transformation from Q1.2\n",
        "\n",
        "**Apply the transformations to all four Datasets** (*i.e.*: the Datasets for `usps_trainset`, `usps_testset`, `mnist_trainset`, `mnist_testset`).\n",
        "\n",
        "Take particular care that the transformations you are choosing are applicable to the task of matching digits. For example, a transformation that would randomly add black boxes to the images might cover the lower half of a 3, which would make it ambiguosly a 2 or a 3.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YRAcPAmtRLz"
      },
      "source": [
        "# Q1.3 code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXvFksuMsqu5"
      },
      "source": [
        "### Q1.4 Visualising the Tranformations (5 pts)\n",
        "\n",
        "From your newly augmented datasets, **plot 3 images from the MNIST and USPS** (for a total of 6 images) along with the digit number (*e.g.:* in the plot title, as done in Tutorial 3).\n",
        "\n",
        "You can certainly recycle code from Tutorial 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfR4sKFWtUdT"
      },
      "source": [
        "# Q1.4 code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26cpi8Natoij"
      },
      "source": [
        "## Part 2 - Dropout (14 pts)\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ6juIKb8mRs"
      },
      "source": [
        "### Q2.1 Illustrating Dropout (5 pts)\n",
        "\n",
        "Prepare 1000 samples of size 120 (*i.e.:* $x = \\mathbb{R}^{1000\\times 120}$). Values can be randomly sampled or all ones; just so long as they are non-zero.\n",
        "\n",
        "Apply a \"dropout\" with a 25% chance of zeroing out an input value to your random sample using [`torch.nn.Dropout`](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout).\n",
        "\n",
        "Finally, calculate the average percentage of elements that are equal to zero in each sample and confirm that it is approximately 25%.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14qiz8uHFFJR"
      },
      "source": [
        "# Q2.1 code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLr_2dv4HI9T"
      },
      "source": [
        "### Q2.2 Train with Dropout and Data Augmentation (9 pts)\n",
        "\n",
        "Change the code below (from Tutorial 3) to include at least one Dropout with $p=0.1$.\n",
        "\n",
        "Add as many dropout layers as you see fit between layers that are, in your estimation, the most relevant.\n",
        "\n",
        "Then, use the cell after the next one to run your dropout network and a network without dropout. The cell after that will plot out the Loss and AUC for both models.\n",
        "\n",
        "*N.B.*: Don't overthink the number of dropout layers or their placement. There is more than one correct answer and we're primarily looking an understanding of the purpose of including dropout layers and how it's acheived (*i.e.*: to combat overfitting from overparameterization by zeroing out random elements of the output of layers with many parameters)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2_wyyAehxgl"
      },
      "source": [
        "# This is the neural network architecture\n",
        "# ** This is the code cell you are meant edit to add dropout **\n",
        "# More specifically, the `__init__` and `forward` methods\n",
        "\n",
        "!pip install pytorch-lightning\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pytorch_lightning as pl\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "class MatchingNetworkWithDropout(pl.LightningModule):\n",
        "    def __init__(self, mnist_in, usps_in):\n",
        "        # (Optionally) EDIT ME \n",
        "        super(MatchingNetworkWithDropout, self).__init__()\n",
        "        self.layer1_mnist = nn.Linear(mnist_in, 128)\n",
        "        self.layer1_usps = nn.Linear(usps_in, 128)\n",
        "        \n",
        "        self.layer2 = nn.Linear(128, 64) # shared between the mnist and usps track\n",
        "        self.layer3 = nn.Linear(64, 32) # shared between the mnist and usps track\n",
        "        \n",
        "        self.loss_func = nn.CosineEmbeddingLoss(reduction='sum')\n",
        "    \n",
        "    def forward(self, x1, x2):\n",
        "        # EDIT ME\n",
        "        x1 = F.relu(self.layer1_mnist(x1))\n",
        "        x1 = F.relu(self.layer2(x1))\n",
        "        x1 = torch.tanh(self.layer3(x1))\n",
        "        \n",
        "        x2 = F.relu(self.layer1_usps(x2))\n",
        "        x2 = F.relu(self.layer2(x2))\n",
        "        x2 = torch.tanh(self.layer3(x2))\n",
        "        return x1, x2\n",
        "\n",
        "\n",
        "    def step(self, batch, batch_idx, log_prefix):\n",
        "      (mnist_data, usps_data), (mnist_y, usps_y) = batch\n",
        "      mnist_data = mnist_data.flatten(start_dim=1)\n",
        "      usps_data = usps_data.flatten(start_dim=1)\n",
        "      mnist_embedding, usps_embedding = self(mnist_data, usps_data)\n",
        "\n",
        "      y = (mnist_y == usps_y) * 2 - 1\n",
        "\n",
        "      loss = self.loss_func(mnist_embedding, usps_embedding, y)\n",
        "\n",
        "      self.log(log_prefix + \"loss\", loss, on_step=False, on_epoch=True)\n",
        "\n",
        "      y_hat = torch.round(F.cosine_similarity(mnist_embedding, usps_embedding))\n",
        "\n",
        "      fpr, tpr, thresholds = metrics.roc_curve(y.cpu(), y_hat.cpu().detach().reshape(-1))\n",
        "      auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "      self.log(log_prefix + \"auc\", auc, on_step=False, on_epoch=True, prog_bar=True)\n",
        "      \n",
        "      return loss\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "      return self.step(batch, batch_idx, 'training_')\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "      return self.step(batch, batch_idx, 'val_')\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "      return torch.optim.Adam(self.parameters(), lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWOE0Qv8Ixyj"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class MatchingNetworkNoDropout(pl.LightningModule):\n",
        "    def __init__(self, mnist_in, usps_in):\n",
        "        super(MatchingNetworkNoDropout, self).__init__()\n",
        "        self.layer1_mnist = nn.Linear(mnist_in, 128)\n",
        "        self.layer1_usps = nn.Linear(usps_in, 128)\n",
        "        \n",
        "        self.layer2 = nn.Linear(128, 64) # shared between the mnist and usps track\n",
        "        self.layer3 = nn.Linear(64, 32) # shared between the mnist and usps track\n",
        "        \n",
        "        self.loss_func = nn.CosineEmbeddingLoss(reduction='sum')\n",
        "    \n",
        "    def forward(self, x1, x2):\n",
        "        x1 = F.relu(self.layer1_mnist(x1))\n",
        "        x1 = F.relu(self.layer2(x1))\n",
        "        x1 = torch.tanh(self.layer3(x1))\n",
        "        \n",
        "        x2 = F.relu(self.layer1_usps(x2))\n",
        "        x2 = F.relu(self.layer2(x2))\n",
        "        x2 = torch.tanh(self.layer3(x2))\n",
        "        return x1, x2\n",
        "\n",
        "\n",
        "    def step(self, batch, batch_idx, log_prefix):\n",
        "      (mnist_data, usps_data), (mnist_y, usps_y) = batch\n",
        "      mnist_data = mnist_data.flatten(start_dim=1)\n",
        "      usps_data = usps_data.flatten(start_dim=1)\n",
        "      mnist_embedding, usps_embedding = self(mnist_data, usps_data)\n",
        "\n",
        "      y = (mnist_y == usps_y) * 2 - 1\n",
        "\n",
        "      loss = self.loss_func(mnist_embedding, usps_embedding, y)\n",
        "\n",
        "      self.log(log_prefix + \"loss\", loss, on_step=False, on_epoch=True)\n",
        "\n",
        "      y_hat = torch.round(F.cosine_similarity(mnist_embedding, usps_embedding))\n",
        "\n",
        "      fpr, tpr, thresholds = metrics.roc_curve(y.cpu(), y_hat.cpu().detach().reshape(-1))\n",
        "      auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "      self.log(log_prefix + \"auc\", auc, on_step=False, on_epoch=True, prog_bar=True)\n",
        "      \n",
        "      return loss\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "      return self.step(batch, batch_idx, 'training_')\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "      return self.step(batch, batch_idx, 'val_')\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "      return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
        "\n",
        "class PairedDataset(Dataset):\n",
        "\n",
        "  def __init__(self, mnist_dataset, usps_dataset):\n",
        "    self.mnist_dataset = mnist_dataset\n",
        "    self.usps_dataset = usps_dataset\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return min(len(self.mnist_dataset), len(self.usps_dataset))\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    \n",
        "    mnist_data, mnist_y = self.mnist_dataset[idx]\n",
        "    usps_data, usps_y = self.usps_dataset[idx]\n",
        "\n",
        "    return (mnist_data, usps_data), (mnist_y, usps_y)\n",
        "\n",
        "\n",
        "pdset_train = PairedDataset(mnist_trainset, usps_trainset)\n",
        "pdset_train_loader = torch.utils.data.DataLoader(pdset_train, batch_size=128)\n",
        "\n",
        "pdset_test = PairedDataset(mnist_testset, usps_testset)\n",
        "pdset_test_loader = torch.utils.data.DataLoader(pdset_test, batch_size=128)\n",
        "\n",
        "!curl -O https://dl.sphericalcow.xyz/ecse552/T4/dict_logger.py\n",
        "from dict_logger import DictLogger\n",
        "\n",
        "model_dropout = MatchingNetworkWithDropout(28*28, 16*16)\n",
        "model_no_dropout = MatchingNetworkNoDropout(28*28, 16*16)\n",
        "\n",
        "logger_dropout = DictLogger()\n",
        "logger_no_dropout = DictLogger()\n",
        "\n",
        "num_epochs = 200\n",
        "\n",
        "trainer = pl.Trainer(max_epochs=num_epochs,\n",
        "                     gpus=1, \n",
        "                     progress_bar_refresh_rate=30,\n",
        "                     logger=logger_dropout\n",
        "                     )\n",
        "\n",
        "trainer.fit(model_dropout, pdset_train_loader, pdset_test_loader)\n",
        "\n",
        "trainer = pl.Trainer(max_epochs=num_epochs,\n",
        "                     gpus=1, \n",
        "                     progress_bar_refresh_rate=30,\n",
        "                     logger=logger_no_dropout\n",
        "                     )\n",
        "\n",
        "trainer.fit(model_no_dropout, pdset_train_loader, pdset_test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yR5ZuKALqGZZ"
      },
      "source": [
        "# This cell plots the Loss and AUC of the models with and without dropout\n",
        "\n",
        "parameters = {'axes.labelsize': 18, 'legend.fontsize': 18, 'xtick.labelsize':16,\n",
        "              'ytick.labelsize':16, 'axes.titlesize': 20}\n",
        "plt.rcParams.update(parameters)\n",
        "\n",
        "fig, axs = plt.subplots(2,2, figsize=(10, 6))\n",
        "\n",
        "axs[0,0].plot(range(num_epochs), logger_dropout.metrics['training_loss'], lw=2, label='Training')\n",
        "axs[0,0].plot(range(num_epochs), logger_dropout.metrics['val_loss'], lw=2, label='Testing')\n",
        "axs[0,0].set_xlabel('Epoch')\n",
        "axs[0,0].set_ylabel('Loss')\n",
        "axs[0,0].set_title('w/ Dropout, Loss')\n",
        "\n",
        "axs[0,1].plot(range(num_epochs), logger_dropout.metrics['training_auc'], lw=2, label='Training')\n",
        "axs[0,1].plot(range(num_epochs), logger_dropout.metrics['val_auc'], lw=2, label='Testing')\n",
        "axs[0,1].set_xlabel('Epoch')\n",
        "axs[0,1].set_ylabel('AUC')\n",
        "axs[0,1].set_title('w/ Dropout, AUC')\n",
        "\n",
        "axs[1,0].plot(range(num_epochs), logger_no_dropout.metrics['training_loss'], lw=2, label='Training')\n",
        "axs[1,0].plot(range(num_epochs), logger_no_dropout.metrics['val_loss'], lw=2, label='Testing')\n",
        "axs[1,0].set_xlabel('Epoch')\n",
        "axs[1,0].set_ylabel('Loss')\n",
        "axs[1,0].set_title('No Dropout, Loss')\n",
        "\n",
        "axs[1,1].plot(range(num_epochs), logger_no_dropout.metrics['training_auc'], lw=2, label='Training')\n",
        "axs[1,1].plot(range(num_epochs), logger_no_dropout.metrics['val_auc'], lw=2, label='Testing')\n",
        "axs[1,1].set_xlabel('Epoch')\n",
        "axs[1,1].set_ylabel('AUC')\n",
        "axs[1,1].set_title('No Dropout, AUC')\n",
        "\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzO2dcCrC6gO"
      },
      "source": [
        "## Part 3 - Theoretical Questions (50 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGFFS2ZwDEzm"
      },
      "source": [
        "### Question 3.1 (25 pts)\n",
        "#### Question 3.1.1 (9 pts)\n",
        "\n",
        "Consider the Taylor series approximation of a function using a quadratic function:\n",
        "\n",
        "$$\n",
        "y = f(\\textrm{x} + \\Delta \\textrm{x}) \\approx f(\\textrm{x}) + \\nabla f(\\textrm{x}) \\Delta \\textrm{x} + \\frac{1}{2} \\Delta \\textrm{x}^\\textrm{T} \\textrm{H}(\\textrm{x})\\Delta \\textrm{x}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\nabla f(\\textrm{x} + \\Delta\\textrm{x}) = \\nabla f(\\textrm{x}) + \\textrm{H}(\\textrm{x})\\Delta \\textrm{x} + \\mathcal{O}(||\\Delta\\textrm{x}||^2)\n",
        "$$\n",
        "\n",
        "Use this to approximate a regularized cost function $\\tilde{J}(w; X, y) = \\frac{\\alpha}{2}w^\\textrm{T}w + J(w; X,y)$ to assess its behaviour in the neighborhood of $w^* = \\textrm{argmin}_w J(w)$. Note that you have seen the final result of this approximation in the class. The goal here is to fill in the missing steps that allowed us to obtain the results we saw in the lecture. As a result, make sure to include and explain each step necessary for this approximation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKHiw-Y3Kjvz"
      },
      "source": [
        "#### Question 3.1.2 (8 pts)\n",
        "\n",
        "Evaluate the above results for a quadratic cost $J(w; X,y)$ and obtain closed-form expressions for the weights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TreQdS-TKtSW"
      },
      "source": [
        "#### Question 3.1.3 (8 pts)\n",
        "\n",
        "Evaluate the above results for a polynomial of degree the three cost $J(w; X, y)$ and simplify the solutions as much as possible.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DngVKPOlMmDV"
      },
      "source": [
        "### Question 3.2 (25 pts)\n",
        "\n",
        "In the class we saw that using quadratic approximation of cost function in the neighborhood of unregularized cost function ($w^*$), the solution of the L2 regularized cost (assuming that there are no biases) is equal to\n",
        "\n",
        "$$\n",
        "\\tilde{w} = \\left(Q\\Lambda Q^\\textrm{T} + \\alpha I\\right)^{-1}Q\\Lambda Q^\\textrm{T}w^*\n",
        "$$\n",
        "\n",
        "$$\n",
        "= \\left[Q(\\Lambda + \\alpha I)Q^\\textrm{T}\\right]Q\\Lambda Q^\\textrm{T}w^*\n",
        "$$\n",
        "\n",
        "$$\n",
        "= Q(\\Lambda + \\alpha I)^{-1} \\Lambda Q^\\textrm{T}w^*\n",
        "$$\n",
        "\n",
        "In these equations, $Q$ is the orthonormal matrix of eigenvector of the Hessian matrix $H$ of $J$ with respect to parameters $w$ evaluated at $w^*$ and $\\Lambda$ is the diagonal matrix of its eigenvalues. Using a similar approximation, we want to evaluate under which condition early stopping and L2 regularization are equivalent.\n",
        "\n",
        "Assume that we initialized the weights from origin and the learning rate $\\epsilon$ is small enough such that $|1-\\epsilon\\lambda_i|<1$. Obtain an expression for $w^t$, the vector of parameters after $t$ iterations using gradient descent as a function of $H, w^*, \\Lambda$ and $\\epsilon$ (the learning rate). Hint: start by describing $w^t$ as a function of $w^{t-1}$ and solve this recursive formula based on the initial vector of weights. \n",
        "\n",
        "**Make sure that you clearly explain and justify each step (only writing down the final results is not sufficient).**\n",
        "\n",
        "Now, compare the expression obtained for $w^t$ with the solution of the weights for L2 regularization in the equation above and find conditions (based on eigenvalues, coefficient of L2 regularization and the learning rate) that if satisfied make the two regularization methods equivalent."
      ]
    }
  ]
}